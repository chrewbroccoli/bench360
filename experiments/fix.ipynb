{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c4baa0",
   "metadata": {},
   "source": [
    "#### Check missing / duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaeec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "DETAILS_DIR = Path(\"/home/ubuntu/fast_llm_inference/RQ1_A30/details\")\n",
    "\n",
    "CONFIG_MODELS = \"\"\"\n",
    "# Qwen2.5\n",
    "- Qwen/Qwen2.5-1.5B-Instruct\n",
    "- Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int4\n",
    "- Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int8\n",
    "- Qwen/Qwen2.5-3B-Instruct\n",
    "- Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\n",
    "- Qwen/Qwen2.5-3B-Instruct-GPTQ-Int8\n",
    "- Qwen/Qwen2.5-7B-Instruct\n",
    "- Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\n",
    "- Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8\n",
    "- Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4\n",
    "- Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8\n",
    "- Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4\n",
    "\n",
    "# Mistral\n",
    "- mistralai/Mistral-7B-Instruct-v0.3\n",
    "- marinarosell/Mistral-7B-Instruct-v0.3-GPTQ-8bit-gs128\n",
    "- marinarosell/Mistral-7B-Instruct-v0.3-GPTQ-4bit-gs128\n",
    "- dwetzel/Mistral-Small-24B-Instruct-2501-GPTQ-INT4\n",
    "\n",
    "# Gemma-2\n",
    "- google/gemma-2-2b-it\n",
    "- marcinbrzezanski/gemma-2-2b-it-gptq\n",
    "- RedHatAI/gemma-2-2b-it-quantized.w8a16\n",
    "- google/gemma-2-9b-it\n",
    "- shuyuej/gemma-2-9b-it-GPTQ\n",
    "- RedHatAI/gemma-2-9b-it-quantized.w8a16\n",
    "- shuyuej/gemma-2-27b-it-GPTQ\n",
    "\n",
    "# LLaMA 3.x\n",
    "- meta-llama/Llama-3.2-1B-Instruct\n",
    "- clowman/Llama-3.2-1B-Instruct-GPTQ-Int4\n",
    "- clowman/Llama-3.2-1B-Instruct-GPTQ-Int8\n",
    "- meta-llama/Llama-3.2-3B-Instruct\n",
    "- clowman/Llama-3.2-3B-Instruct-GPTQ-Int8\n",
    "- clowman/Llama-3.2-3B-Instruct-GPTQ-Int4\n",
    "- meta-llama/Llama-3.1-8B-Instruct\n",
    "- clowman/Llama-3.1-8B-Instruct-GPTQ-Int4\n",
    "- clowman/Llama-3.1-8B-Instruct-GPTQ-Int8\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "expected_models = [m.split(\"/\")[-1] for m in yaml.safe_load(CONFIG_MODELS)]\n",
    "tasks = [\"qa\", \"sql\", \"summarization\"]\n",
    "\n",
    "# 1️⃣  Scan all CSVs\n",
    "existing_files = list(DETAILS_DIR.glob(\"*.csv\"))\n",
    "\n",
    "# helper → strip “vllm_” prefix and trailing “_<8-hex>.csv”\n",
    "def normalize(fname: str) -> str:\n",
    "    core = re.sub(r\"^vllm_\", \"\", fname)\n",
    "    return re.sub(r\"_[a-f0-9]{8}\\.csv$\", \"\", core)\n",
    "\n",
    "# Build presence map and duplicate map\n",
    "present = {m: {t: False for t in tasks} for m in expected_models}\n",
    "dupes: dict[str, list[str]] = {}\n",
    "\n",
    "for f in existing_files:\n",
    "    norm = normalize(f.name)                       # e.g. Llama-..._qa_batch_bs16\n",
    "    dupes.setdefault(norm, []).append(f.name)      # collect for duplicate check\n",
    "\n",
    "    parts = norm.split(\"_\")\n",
    "    if len(parts) < 4:\n",
    "        continue\n",
    "    model_id = \"_\".join(parts[:-3])\n",
    "    task      = parts[-3]\n",
    "    if model_id in present and task in present[model_id]:\n",
    "        present[model_id][task] = True\n",
    "\n",
    "# 2️⃣  “Which runs are still missing?”\n",
    "records = []\n",
    "for model in expected_models:\n",
    "    st = present[model]\n",
    "    records.append(\n",
    "        {\"Model\": model, \"qa\": st[\"qa\"], \"sql\": st[\"sql\"],\n",
    "         \"summarization\": st[\"summarization\"], \"Complete\": all(st.values())}\n",
    "    )\n",
    "missing_df = pd.DataFrame(records).sort_values(\"Model\")\n",
    "\n",
    "# 3️⃣  “Which runs are duplicated (same model+task, different hashes)?”\n",
    "dup_records = [\n",
    "    {\"Normalized name\": k, \"Count\": len(v), \"Files\": \" | \".join(v)}\n",
    "    for k, v in dupes.items() if len(v) > 1\n",
    "]\n",
    "\n",
    "if dup_records:\n",
    "    dupes_df = pd.DataFrame(dup_records).sort_values(\"Count\", ascending=False)\n",
    "else:\n",
    "    dupes_df = pd.DataFrame(columns=[\"Normalized name\", \"Count\", \"Files\"])\n",
    "\n",
    "\n",
    "# 4️⃣  Show / save results\n",
    "print(\"\\n=== Missing (incomplete) runs ===\")\n",
    "print(missing_df[~missing_df[\"Complete\"]])\n",
    "\n",
    "print(\"\\n=== Duplicate CSVs (hash-agnostic) ===\")\n",
    "print(dupes_df if not dupes_df.empty else \"No duplicates 🎉\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4e18e",
   "metadata": {},
   "source": [
    "#### Merge run_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2008f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀  Merged 96 files → /home/ubuntu/fast_llm_inference/RQ1_A30/merged_run_report.csv  (96 rows)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# merge_run_reports.py\n",
    "# Usage: python merge_run_reports.py /home/ubuntu/fast_llm_inference/RQ1_merged_256/run_report\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ─────────────────────────────────────── config\n",
    "RUN_DIR   = Path(\"/home/ubuntu/fast_llm_inference/RQ1_A30/run_report\")\n",
    "OUT_PATH  = RUN_DIR.parent / \"merged_run_report.csv\"\n",
    "\n",
    "# All columns we want in the final file (order matters)\n",
    "FINAL_COLS = [\n",
    "    \"model_name\", \"model_size_mb\", \"task\", \"scenario\", \"backend\",\n",
    "    \"startup\", \"ttft_sec\", \"coldstart\", \"batch_size\", \"num_queries\",\n",
    "    \"total_generation_time_s\", \"avg_gpu_mem_mb\", \"peak_gpu_mem_mb\",\n",
    "    \"overhead_mb\", \"avg_gpu_util_pct\", \"peak_gpu_util_pct\",\n",
    "    \"avg_cpu_util_pct\", \"peak_cpu_util_pct\", \"avg_ram_mb\", \"peak_ram_mb\",\n",
    "    \"avg_power_w\", \"peak_power_w\", \"total_energy_wh\",\n",
    "    \"avg_generation_time\", \"avg_tokens_generated\", \"avg_sentences_generated\",\n",
    "    \"avg_ATL\", \"avg_GL\", \"avg_TPS\", \"avg_SPS\",\n",
    "    \"avg_energy_per_token\", \"avg_energy_per_sentence\"\n",
    "]\n",
    "\n",
    "# Quality‐metric columns we need for pick_quality()\n",
    "QUALITY_COLS = [\"avg_F1_score\", \"avg_AST_equal\", \"avg_ROUGE-1\"]\n",
    "\n",
    "def load_one(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read one run_report CSV and normalize to FINAL_COLS + QUALITY_COLS schema.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Ensure every expected column exists; missing ⇒ NaN\n",
    "    for col in FINAL_COLS + QUALITY_COLS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Keep only the final schema & order\n",
    "    return df[FINAL_COLS + QUALITY_COLS]\n",
    "\n",
    "# ─────────────────────────────────────── main\n",
    "all_csvs = sorted(RUN_DIR.glob(\"*.csv\"))\n",
    "if not all_csvs:\n",
    "    sys.exit(f\"No CSVs found in {RUN_DIR}\")\n",
    "\n",
    "# Load & normalize each, then concatenate\n",
    "merged = pd.concat([load_one(p) for p in all_csvs], ignore_index=True)\n",
    "\n",
    "# ── write out ───────────────────────────────────────────────────────\n",
    "merged.to_csv(OUT_PATH, index=False)\n",
    "print(f\"🚀  Merged {len(all_csvs)} files → {OUT_PATH}  ({len(merged)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a10205",
   "metadata": {},
   "source": [
    "#### Merge details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74018817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀  Merged 96 files → /home/ubuntu/fast_llm_inference/RQ1_A30/merged_details.csv  (24576 rows)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# merge_benchmark_details.py\n",
    "# Usage:  python merge_benchmark_details.py /home/ubuntu/fast_llm_inference/RQ1_merged/details\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ─────────────────────────────────────── config\n",
    "DETAILS_DIR     = Path(\"/home/ubuntu/fast_llm_inference/RQ1_A30/details\")\n",
    "OUT_PATH        = DETAILS_DIR.parent / \"merged_details.csv\"\n",
    "\n",
    "# All columns we want in the final file (order matters)\n",
    "FINAL_COLS = [\n",
    "    \"backend\", \"model\", \"task\",\n",
    "    \"generated_answer\", \"reference_answer\",\n",
    "    \"generation_time\", \"tokens_generated\", \"sentences_generated\",\n",
    "    \"ATL\", \"GL\", \"TPS\", \"SPS\",\n",
    "    \"energy_per_token\", \"energy_per_sentence\",\n",
    "    \"exact_match\", \"F1_score\",\n",
    "    \"AST_equal\", \"Normalized_equal\",\n",
    "    \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"\n",
    "]\n",
    "\n",
    "# Regex to pull <backend>, <model>, <task> from the filename\n",
    "PAT = re.compile(\n",
    "    r\"\"\"^(?P<backend>[^_]+)_           # vllm, tgi …\n",
    "        (?P<model>.+?)_                # greedy until _<task>_\n",
    "        (?P<task>qa|sql|summarization) # capture task\n",
    "        _[^/]*\\.csv$                   # rest is scenario, hash …\n",
    "    \"\"\", re.X | re.I)\n",
    "\n",
    "def load_one(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read a single details-CSV and normalise its columns.\"\"\"\n",
    "    m = PAT.match(path.name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse '{path.name}'\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Drop prompt – we don't need it in the merged file\n",
    "    df = df.drop(columns=[c for c in df.columns if c.lower() == \"prompt\"], errors=\"ignore\")\n",
    "\n",
    "    # Inject backend / model / task from filename\n",
    "    for k, v in m.groupdict().items():\n",
    "        df[k] = v\n",
    "\n",
    "    # Make sure every expected column exists; missing ⇒ NaN\n",
    "    for col in FINAL_COLS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Keep only the final schema & order\n",
    "    return df[FINAL_COLS]\n",
    "\n",
    "# ─────────────────────────────────────── main\n",
    "all_csvs = sorted(DETAILS_DIR.glob(\"*.csv\"))\n",
    "if not all_csvs:\n",
    "    sys.exit(f\"No CSVs found in {DETAILS_DIR}\")\n",
    "\n",
    "merged = pd.concat([load_one(p) for p in all_csvs], ignore_index=True)\n",
    "merged.to_csv(OUT_PATH, index=False)\n",
    "print(f\"🚀  Merged {len(all_csvs)} files → {OUT_PATH}  ({len(merged)} rows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4994d5",
   "metadata": {},
   "source": [
    "#### Adding SQL execution accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sql_task = SQLTask(\n",
    "    db_root=\"/home/ubuntu/fast_llm_inference/benchmark/lookup/database\",\n",
    "    tables_path=\"/home/ubuntu/fast_llm_inference/benchmark/lookup/tables.json\"\n",
    ")\n",
    "df_sql_id = pd.DataFrame(sql_task.generate_prompts(num_examples=256)[1:])\n",
    "df_sql_id = df_sql_id.T            # flips rows↔columns\n",
    "df_sql_id.columns = [\"reference\", \"db_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "963e3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/home/ubuntu/fast_llm_inference/RQ1_A30/merged_details.csv\"\n",
    "merged = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7936 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7936/7936 [00:29<00:00, 269.60it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Exec_accuracy_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fastllm_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Exec_accuracy_new'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     40\u001b[39m merged_full = pd.merge(\n\u001b[32m     41\u001b[39m     merged_full,\n\u001b[32m     42\u001b[39m     sql_eval[[\u001b[33m\"\u001b[39m\u001b[33mreference_answer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mExec_accuracy\u001b[39m\u001b[33m\"\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     suffixes=(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_new\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# 7️⃣ Prioritize new values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m merged_full[\u001b[33m\"\u001b[39m\u001b[33mExec_accuracy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mmerged_full\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExec_accuracy_new\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.combine_first(merged_full[\u001b[33m\"\u001b[39m\u001b[33mExec_accuracy\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 8️⃣ Drop temp column\u001b[39;00m\n\u001b[32m     52\u001b[39m merged_full.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mExec_accuracy_new\u001b[39m\u001b[33m\"\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fastllm_venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fastllm_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Exec_accuracy_new'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1️⃣ Load full merged CSV\n",
    "csv_path = \"/home/ubuntu/fast_llm_inference/RQ1_A30/merged_details.csv\"\n",
    "merged_full = pd.read_csv(csv_path)\n",
    "\n",
    "# 2️⃣ Build a mapping: reference → db_id\n",
    "ref2db = dict(zip(df_sql_id[\"reference\"], df_sql_id[\"db_id\"]))\n",
    "\n",
    "# 3️⃣ Add and fill db_id column\n",
    "merged_full[\"db_id\"] = pd.Series(dtype=\"object\")\n",
    "sql_mask = merged_full[\"task\"].str.lower() == \"sql\"\n",
    "merged_full.loc[sql_mask, \"db_id\"] = merged_full.loc[sql_mask, \"reference_answer\"].map(ref2db)\n",
    "\n",
    "# 4️⃣ Filter SQL rows with valid db_id, excluding 'formula_1'\n",
    "sql_eval = merged_full[\n",
    "    (merged_full[\"task\"].str.lower() == \"sql\") &\n",
    "    (merged_full[\"db_id\"].notnull()) &\n",
    "    (merged_full[\"db_id\"] != \"formula_1\")\n",
    "].copy()\n",
    "\n",
    "# 5️⃣ Evaluate SQL quality metrics\n",
    "sql_eval.reset_index(drop=True, inplace=True)\n",
    "sql_eval[\"Exec_accuracy\"] = np.nan\n",
    "\n",
    "for i, row in tqdm(sql_eval.iterrows(), total=len(sql_eval)):\n",
    "    try:\n",
    "        result = sql_task.quality_metrics(\n",
    "            generated=row[\"generated_answer\"],\n",
    "            reference=row[\"reference_answer\"],\n",
    "            db_id=row[\"db_id\"]\n",
    "        )\n",
    "        sql_eval.at[i, \"Exec_accuracy\"] = result.get(\"Exec_accuracy\", np.nan)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Row {i} failed: {e}\")\n",
    "\n",
    "# 6️⃣ Merge Exec_accuracy back into full DataFrame (safe for duplicate keys)\n",
    "merged_full = pd.merge(\n",
    "    merged_full,\n",
    "    sql_eval[[\"reference_answer\", \"Exec_accuracy\"]],\n",
    "    on=\"reference_answer\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_new\")\n",
    ")\n",
    "\n",
    "# 7️⃣ Prioritize new values\n",
    "merged_full[\"Exec_accuracy\"] = merged_full[\"Exec_accuracy_new\"].combine_first(merged_full[\"Exec_accuracy\"])\n",
    "\n",
    "# 8️⃣ Drop temp column\n",
    "merged_full.drop(columns=[\"Exec_accuracy_new\"], inplace=True)\n",
    "\n",
    "# 9️⃣ (Optional) Save to disk\n",
    "merged_full.to_csv(\"RQ1_A30_with_exec_accuracy.csv\", index=False)y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5b7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5282258064516129"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[(merged['model'] == \"Mistral-Small-24B-Instruct-2501-GPTQ-INT4\") & (merged['task'] == \"sql\")][\"Exec_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5332a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"/home/ubuntu/fast_llm_inference/RQ1_A30/merged_details_with_exec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adcc0d9",
   "metadata": {},
   "source": [
    "#### Add GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f28c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Saved: /home/ubuntu/fast_llm_inference/RQ1_A30/merged_run_report_info_with_gpu_ci95.csv\n",
      "Matched:   96\n",
      "Unmatched: 0\n",
      "Skipped:   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ─── 1️⃣ Load df_report ──────────────────────────────────────────\n",
    "df_report = pd.read_csv(\"/home/ubuntu/fast_llm_inference/RQ1_A30/merged_run_report.csv\")\n",
    "df_report[\"gpu_util_pct\"] = None\n",
    "df_report[\"gpu_util_pct_ci95\"] = None\n",
    "\n",
    "# ─── 2️⃣ File listing ────────────────────────────────────────────\n",
    "readings_dir = \"/home/ubuntu/fast_llm_inference/RQ1_A30/readings\"\n",
    "files = [f for f in os.listdir(readings_dir) if f.endswith(\".csv\") and f.startswith(\"ts_\")]\n",
    "\n",
    "matched, unmatched, skipped = 0, 0, 0\n",
    "\n",
    "# ─── 3️⃣ Process each reading file ───────────────────────────────\n",
    "for fname in files:\n",
    "    path = os.path.join(readings_dir, fname)\n",
    "    stem = fname.removesuffix(\".csv\")\n",
    "\n",
    "    # Remove ts_ prefix\n",
    "    if not stem.startswith(\"ts_\"):\n",
    "        skipped += 1\n",
    "        continue\n",
    "    stem = stem[3:]\n",
    "\n",
    "    parts = stem.split(\"_\")\n",
    "\n",
    "    if len(parts) < 5:\n",
    "        print(f\"❌ Too few parts in filename: {fname}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Extract metadata\n",
    "    backend  = parts[0].strip().lower()\n",
    "    model = parts[1].strip()\n",
    "    task     = parts[2].strip().lower()\n",
    "    scenario = parts[3].strip().lower()\n",
    "\n",
    "    # Validate\n",
    "    valid_tasks = {\"sql\", \"qa\", \"summarization\"}\n",
    "    valid_scenarios = {\"single\", \"batch\", \"server\"}\n",
    "    valid_backends = {\"vllm\", \"tgi\", \"sglang\", \"lmdeploy\"}\n",
    "\n",
    "    if task not in valid_tasks or scenario not in valid_scenarios or backend not in valid_backends:\n",
    "        print(f\"⚠️ Unknown task or scenario in {fname}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Read readings file\n",
    "    try:\n",
    "        df_reading = pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {fname}: {e}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if \"gpu_util_pct\" not in df_reading.columns:\n",
    "        print(f\"⚠️ Skipping {fname} — 'gpu_util_pct' missing\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Compute mean and CI95\n",
    "    gpu_vals = df_reading[\"gpu_util_pct\"].dropna()\n",
    "    mean_val = gpu_vals.mean()\n",
    "    std_val  = gpu_vals.std()\n",
    "    n_val    = gpu_vals.count()\n",
    "    ci95_val = 1.96 * std_val / (n_val ** 0.5) if n_val > 1 else 0.0\n",
    "\n",
    "    # Find corresponding row\n",
    "    mask = (\n",
    "        (df_report[\"model_name\"] == model)\n",
    "        & (df_report[\"task\"].str.lower() == task)\n",
    "        & (df_report[\"scenario\"].str.lower() == scenario)\n",
    "        & (df_report[\"backend\"].str.lower() == backend)\n",
    "    )\n",
    "\n",
    "    if mask.sum() == 1:\n",
    "        df_report.loc[mask, \"gpu_util_pct\"] = mean_val\n",
    "        df_report.loc[mask, \"gpu_util_pct_ci95\"] = ci95_val\n",
    "        matched += 1\n",
    "    elif mask.sum() == 0:\n",
    "        print(f\"❌ No match for model={model}, task={task}, scenario={scenario}, backend={backend}\")\n",
    "        unmatched += 1\n",
    "    else:\n",
    "        print(f\"⚠️ Multiple matches for model={model}, task={task}, scenario={scenario}, backend={backend}\")\n",
    "        unmatched += 1\n",
    "\n",
    "# ─── 4️⃣ Save updated report ─────────────────────────────────────\n",
    "out_path = \"/home/ubuntu/fast_llm_inference/RQ1_A30/merged_run_report_with_gpu_ci95.csv\"\n",
    "df_report.to_csv(out_path, index=False)\n",
    "\n",
    "# ─── 5️⃣ Summary ─────────────────────────────────────────────────\n",
    "print(f\"✅ Done. Saved: {out_path}\")\n",
    "print(f\"Matched:   {matched}\")\n",
    "print(f\"Unmatched: {unmatched}\")\n",
    "print(f\"Skipped:   {skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c826e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_size_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>13824.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>13824.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>13824.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Mistral-Small-24B-Instruct-2501-GPTQ-INT4</td>\n",
       "      <td>13492.045288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Mistral-Small-24B-Instruct-2501-GPTQ-INT4</td>\n",
       "      <td>13492.045288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mistral-Small-24B-Instruct-2501-GPTQ-INT4</td>\n",
       "      <td>13492.045288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Qwen2.5-14B-Instruct-GPTQ-Int8</td>\n",
       "      <td>15875.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Qwen2.5-14B-Instruct-GPTQ-Int8</td>\n",
       "      <td>15875.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Qwen2.5-14B-Instruct-GPTQ-Int8</td>\n",
       "      <td>15875.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Qwen2.5-32B-Instruct-GPTQ-Int4</td>\n",
       "      <td>18447.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Qwen2.5-32B-Instruct-GPTQ-Int4</td>\n",
       "      <td>18447.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Qwen2.5-32B-Instruct-GPTQ-Int4</td>\n",
       "      <td>18447.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>14525.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>14525.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>14525.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>gemma-2-27b-it-GPTQ</td>\n",
       "      <td>17418.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gemma-2-27b-it-GPTQ</td>\n",
       "      <td>17418.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>gemma-2-27b-it-GPTQ</td>\n",
       "      <td>17418.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>17627.155273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>17627.155273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>17627.155273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model_name  model_size_mb\n",
       "33                   Mistral-7B-Instruct-v0.3   13824.507812\n",
       "34                   Mistral-7B-Instruct-v0.3   13824.507812\n",
       "35                   Mistral-7B-Instruct-v0.3   13824.507812\n",
       "36  Mistral-Small-24B-Instruct-2501-GPTQ-INT4   13492.045288\n",
       "37  Mistral-Small-24B-Instruct-2501-GPTQ-INT4   13492.045288\n",
       "38  Mistral-Small-24B-Instruct-2501-GPTQ-INT4   13492.045288\n",
       "51             Qwen2.5-14B-Instruct-GPTQ-Int8   15875.072266\n",
       "52             Qwen2.5-14B-Instruct-GPTQ-Int8   15875.072266\n",
       "53             Qwen2.5-14B-Instruct-GPTQ-Int8   15875.072266\n",
       "54             Qwen2.5-32B-Instruct-GPTQ-Int4   18447.634766\n",
       "55             Qwen2.5-32B-Instruct-GPTQ-Int4   18447.634766\n",
       "56             Qwen2.5-32B-Instruct-GPTQ-Int4   18447.634766\n",
       "72                        Qwen2.5-7B-Instruct   14525.635742\n",
       "73                        Qwen2.5-7B-Instruct   14525.635742\n",
       "74                        Qwen2.5-7B-Instruct   14525.635742\n",
       "75                        gemma-2-27b-it-GPTQ   17418.012695\n",
       "76                        gemma-2-27b-it-GPTQ   17418.012695\n",
       "77                        gemma-2-27b-it-GPTQ   17418.012695\n",
       "93                              gemma-2-9b-it   17627.155273\n",
       "94                              gemma-2-9b-it   17627.155273\n",
       "95                              gemma-2-9b-it   17627.155273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_include = [\n",
    "    \"Mistral-7B-Instruct-v0.3\", \"Mistral-Small-24B-Instruct-2501-GPTQ-INT4\",\n",
    "    \"gemma-2-9b-it\", \"gemma-2-27b-it-GPTQ\",\n",
    "    \"Qwen2.5-7B-Instruct\", \"Qwen2.5-14B-Instruct-GPTQ-Int8\", \"Qwen2.5-32B-Instruct-GPTQ-Int4\"\n",
    "]\n",
    "\n",
    "filtered_sizes = df_report[df_report['model_name'].isin(model_include)][['model_name', 'model_size_mb']]\n",
    "\n",
    "filtered_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147276e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'generated_answer', 'reference_answer', 'generation_time',\n",
       "       'tokens_generated', 'sentences_generated', 'ATL', 'GL', 'TPS', 'SPS',\n",
       "       'energy_per_token', 'energy_per_sentence', 'ROUGE-1', 'ROUGE-2',\n",
       "       'ROUGE-L', 'engine', 'model', 'task', 'use_case', 'AST_equal',\n",
       "       'exact_match', 'F1_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the folder with CSVs\n",
    "data_dir = Path(\"/home/ubuntu/fast_llm_inference/RQ3/details\")\n",
    "all_files = list(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "# Filter for *_single_*.csv files\n",
    "single_files = [f for f in all_files if \"_single_\" in f.stem]\n",
    "\n",
    "# Load and annotate each CSV\n",
    "df_list = []\n",
    "for f in single_files:\n",
    "    parts = f.stem.split(\"_\")\n",
    "    if len(parts) < 4:\n",
    "        continue\n",
    "    engine = parts[0]\n",
    "    model = parts[1]\n",
    "    task = parts[2]\n",
    "    use_case = parts[3]\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"engine\"] = engine\n",
    "    df[\"model\"] = model\n",
    "    df[\"task\"] = task\n",
    "    df[\"use_case\"] = use_case\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "merged_single_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "merged_single_df.to_csv(\"/home/ubuntu/fast_llm_inference/RQ3/merged_single_details.csv\", index=False)\n",
    "\n",
    "merged_single_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf742e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>generation_time</th>\n",
       "      <th>tokens_generated</th>\n",
       "      <th>sentences_generated</th>\n",
       "      <th>ATL</th>\n",
       "      <th>GL</th>\n",
       "      <th>TPS</th>\n",
       "      <th>SPS</th>\n",
       "      <th>...</th>\n",
       "      <th>engine</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>use_case</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT Band.Firstname, Band.Lastname FROM Perf...</td>\n",
       "      <td>SELECT T2.firstname ,  T2.lastname FROM Perfor...</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>70.26</td>\n",
       "      <td>10.81</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT policy_type_code FROM Available_Policies</td>\n",
       "      <td>SELECT DISTINCT t3.policy_type_code FROM custo...</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>64.86</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT station.id, station.name</td>\n",
       "      <td>SELECT DISTINCT T1.id ,  T1.name FROM station ...</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>48.64</td>\n",
       "      <td>10.81</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT customer_name FROM Customers WHERE cust...</td>\n",
       "      <td>SELECT customer_name FROM customers WHERE cust...</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>97.29</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT technician.Name</td>\n",
       "      <td>SELECT T3.Name FROM repair_assignment AS T1 JO...</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>32.43</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35835</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT Advisor FROM Student GROUP BY Advisor H...</td>\n",
       "      <td>SELECT Advisor FROM STUDENT GROUP BY Advisor H...</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>165.79</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35836</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT state, SUM(acc_bal) as total_balance</td>\n",
       "      <td>SELECT sum(acc_bal) ,  state FROM customer WHE...</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>108.13</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35837</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT artist_name, most_popular_in</td>\n",
       "      <td>SELECT artist_name FROM song WHERE resolution ...</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>86.50</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35838</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT Employees.Employee_ID, COUNT(All_Docume...</td>\n",
       "      <td>SELECT Destroyed_by_Employee_ID ,  count(*) FR...</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>237.88</td>\n",
       "      <td>14.42</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35839</th>\n",
       "      <td>### SYSTEM\\nYou are a SQL query generation ass...</td>\n",
       "      <td>SELECT player.name_first, player.name_last</td>\n",
       "      <td>SELECT T2.name_first ,  T2.name_last FROM sala...</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>93.71</td>\n",
       "      <td>14.42</td>\n",
       "      <td>...</td>\n",
       "      <td>vllm</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>sql</td>\n",
       "      <td>batch</td>\n",
       "      <td>bs64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35840 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "1      ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "2      ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "3      ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "4      ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "...                                                  ...   \n",
       "35835  ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "35836  ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "35837  ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "35838  ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "35839  ### SYSTEM\\nYou are a SQL query generation ass...   \n",
       "\n",
       "                                        generated_answer  \\\n",
       "0      SELECT Band.Firstname, Band.Lastname FROM Perf...   \n",
       "1        SELECT policy_type_code FROM Available_Policies   \n",
       "2                        SELECT station.id, station.name   \n",
       "3      SELECT customer_name FROM Customers WHERE cust...   \n",
       "4                                 SELECT technician.Name   \n",
       "...                                                  ...   \n",
       "35835  SELECT Advisor FROM Student GROUP BY Advisor H...   \n",
       "35836        SELECT state, SUM(acc_bal) as total_balance   \n",
       "35837                SELECT artist_name, most_popular_in   \n",
       "35838  SELECT Employees.Employee_ID, COUNT(All_Docume...   \n",
       "35839         SELECT player.name_first, player.name_last   \n",
       "\n",
       "                                        reference_answer  generation_time  \\\n",
       "0      SELECT T2.firstname ,  T2.lastname FROM Perfor...         0.185022   \n",
       "1      SELECT DISTINCT t3.policy_type_code FROM custo...         0.185022   \n",
       "2      SELECT DISTINCT T1.id ,  T1.name FROM station ...         0.185022   \n",
       "3      SELECT customer_name FROM customers WHERE cust...         0.185022   \n",
       "4      SELECT T3.Name FROM repair_assignment AS T1 JO...         0.185022   \n",
       "...                                                  ...              ...   \n",
       "35835  SELECT Advisor FROM STUDENT GROUP BY Advisor H...         0.138727   \n",
       "35836  SELECT sum(acc_bal) ,  state FROM customer WHE...         0.138727   \n",
       "35837  SELECT artist_name FROM song WHERE resolution ...         0.138727   \n",
       "35838  SELECT Destroyed_by_Employee_ID ,  count(*) FR...         0.138727   \n",
       "35839  SELECT T2.name_first ,  T2.name_last FROM sala...         0.138727   \n",
       "\n",
       "       tokens_generated  sentences_generated       ATL        GL     TPS  \\\n",
       "0                    13                    2  0.014232  0.185022   70.26   \n",
       "1                    12                    1  0.015419  0.185022   64.86   \n",
       "2                     9                    2  0.020558  0.185022   48.64   \n",
       "3                    18                    1  0.010279  0.185022   97.29   \n",
       "4                     6                    1  0.030837  0.185022   32.43   \n",
       "...                 ...                  ...       ...       ...     ...   \n",
       "35835                23                    1  0.006032  0.138727  165.79   \n",
       "35836                15                    1  0.009248  0.138727  108.13   \n",
       "35837                12                    1  0.011561  0.138727   86.50   \n",
       "35838                33                    2  0.004204  0.138727  237.88   \n",
       "35839                13                    2  0.010671  0.138727   93.71   \n",
       "\n",
       "         SPS  ...  engine                     model  task use_case batch_size  \\\n",
       "0      10.81  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs32   \n",
       "1       5.40  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs32   \n",
       "2      10.81  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs32   \n",
       "3       5.40  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs32   \n",
       "4       5.40  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs32   \n",
       "...      ...  ...     ...                       ...   ...      ...        ...   \n",
       "35835   7.21  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs64   \n",
       "35836   7.21  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs64   \n",
       "35837   7.21  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs64   \n",
       "35838  14.42  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs64   \n",
       "35839  14.42  ...    vllm  Mistral-7B-Instruct-v0.3   sql    batch       bs64   \n",
       "\n",
       "      ROUGE-1 ROUGE-2 ROUGE-L  exact_match  F1_score  \n",
       "0         NaN     NaN     NaN          NaN       NaN  \n",
       "1         NaN     NaN     NaN          NaN       NaN  \n",
       "2         NaN     NaN     NaN          NaN       NaN  \n",
       "3         NaN     NaN     NaN          NaN       NaN  \n",
       "4         NaN     NaN     NaN          NaN       NaN  \n",
       "...       ...     ...     ...          ...       ...  \n",
       "35835     NaN     NaN     NaN          NaN       NaN  \n",
       "35836     NaN     NaN     NaN          NaN       NaN  \n",
       "35837     NaN     NaN     NaN          NaN       NaN  \n",
       "35838     NaN     NaN     NaN          NaN       NaN  \n",
       "35839     NaN     NaN     NaN          NaN       NaN  \n",
       "\n",
       "[35840 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import necessary modules due to code execution environment reset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Re-define path and find all CSVs again\n",
    "data_dir = Path(\"/home/ubuntu/fast_llm_inference/RQ3/details\")\n",
    "all_files = list(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "# Filter for *_batch_*.csv files\n",
    "batch_files = [f for f in all_files if \"_batch_\" in f.stem]\n",
    "\n",
    "# Load and annotate each CSV\n",
    "batch_df_list = []\n",
    "for f in batch_files:\n",
    "    parts = f.stem.split(\"_\")\n",
    "    if len(parts) < 4:\n",
    "        continue\n",
    "    engine = parts[0]\n",
    "    model = parts[1]\n",
    "    task = parts[2]\n",
    "    use_case = parts[3]\n",
    "    batch_size = parts[4]\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"engine\"] = engine\n",
    "    df[\"model\"] = model\n",
    "    df[\"task\"] = task\n",
    "    df[\"use_case\"] = use_case\n",
    "    df[\"batch_size\"] = batch_size\n",
    "    batch_df_list.append(df)\n",
    "\n",
    "# Concatenate into one DataFrame\n",
    "merged_batch_df = pd.concat(batch_df_list, ignore_index=True)\n",
    "\n",
    "merged_batch_df.to_csv(\"/home/ubuntu/fast_llm_inference/RQ3/merged_batch_details.csv\", index=False)\n",
    "\n",
    "merged_batch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d54faf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mistral-7B-Instruct-v0.3', 'Qwen2.5-3B-Instruct',\n",
       "       'Llama-3.1-8B-Instruct'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_batch_df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2293fa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>scheduled_ts</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>send_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>queue_time</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>e2e_latency</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>...</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>engine</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>use_case</th>\n",
       "      <th>concurrent_users</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AST_equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>30.356503</td>\n",
       "      <td>1.751223e+09</td>\n",
       "      <td>1.751223e+09</td>\n",
       "      <td>1.751223e+09</td>\n",
       "      <td>19.540525</td>\n",
       "      <td>19.540696</td>\n",
       "      <td>29.187121</td>\n",
       "      <td>Liverpool advanced to the FA Cup semi-finals w...</td>\n",
       "      <td>Coutinho hit the only goal of the game as Live...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>tgi</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>summarization</td>\n",
       "      <td>server</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  scheduled_ts   submit_time     send_time    start_time  \\\n",
       "0        5     30.356503  1.751223e+09  1.751223e+09  1.751223e+09   \n",
       "\n",
       "   queue_time  wait_time  e2e_latency  \\\n",
       "0   19.540525  19.540696    29.187121   \n",
       "\n",
       "                                    generated_answer  \\\n",
       "0  Liverpool advanced to the FA Cup semi-finals w...   \n",
       "\n",
       "                                    reference_answer  ...   ROUGE-2   ROUGE-L  \\\n",
       "0  Coutinho hit the only goal of the game as Live...  ...  0.109375  0.184615   \n",
       "\n",
       "   engine                  model           task  use_case  concurrent_users  \\\n",
       "0     tgi  Llama-3.1-8B-Instruct  summarization    server                16   \n",
       "\n",
       "   exact_match  F1_score  AST_equal  \n",
       "0          NaN       NaN        NaN  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_server_df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-generation-server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
